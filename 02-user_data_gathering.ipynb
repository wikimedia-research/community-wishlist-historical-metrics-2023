{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f37b9564-2a5f-4349-8127-c599a2bbe9cd",
   "metadata": {},
   "source": [
    "# Step 2: gather user data\n",
    "For each username, gather:\n",
    "* Home-wiki\n",
    "    + wiki with highest number of edits during the prceeding two years\n",
    "* Edit bucket on home-wiki\n",
    "* Edit bucket on Meta Wiki\n",
    "* User rights on home-wiki\n",
    "* User account age"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02ec8bae-cb93-4e7c-af6a-29c6f68ebcab",
   "metadata": {},
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2207e61f-16e0-4f46-8505-d132e9d1519f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You are using Wmfdata v2.0.0, but v2.0.1 is available.\n",
      "\n",
      "To update, run `pip install --upgrade git+https://github.com/wikimedia/wmfdata-python.git@release`.\n",
      "\n",
      "To see the changes, refer to https://github.com/wikimedia/wmfdata-python/blob/release/CHANGELOG.md.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import wmfdata as wmf\n",
    "\n",
    "pd.options.display.max_columns = None\n",
    "from IPython.display import clear_output\n",
    "\n",
    "import warnings\n",
    "import json\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "56e69083-bc64-4f7d-8ba7-2de548ea3b26",
   "metadata": {},
   "outputs": [],
   "source": [
    "# mediawiki snapshot\n",
    "snapshot = '2023-09'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "147c8140-3b07-42b9-aa28-a70fcc55a5f6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "            <div>\n",
       "                <p><b>SparkSession - hive</b></p>\n",
       "                \n",
       "        <div>\n",
       "            <p><b>SparkContext</b></p>\n",
       "\n",
       "            <p><a href=\"http://stat1005.eqiad.wmnet:4045\">Spark UI</a></p>\n",
       "\n",
       "            <dl>\n",
       "              <dt>Version</dt>\n",
       "                <dd><code>v3.1.2</code></dd>\n",
       "              <dt>Master</dt>\n",
       "                <dd><code>yarn</code></dd>\n",
       "              <dt>AppName</dt>\n",
       "                <dd><code>cws-user-data</code></dd>\n",
       "            </dl>\n",
       "        </div>\n",
       "        \n",
       "            </div>\n",
       "        "
      ],
      "text/plain": [
       "<pyspark.sql.session.SparkSession at 0x7f0daf1618d0>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spark_session = wmf.spark.get_active_session()\n",
    "\n",
    "if type(spark_session) == type(None):\n",
    "    spark_session = wmf.spark.create_custom_session(\n",
    "        master=\"yarn\",\n",
    "        app_name='cws-user-data',\n",
    "        spark_config={\n",
    "            \"spark.driver.memory\": \"4g\",\n",
    "            \"spark.dynamicAllocation.maxExecutors\": 64,\n",
    "            \"spark.executor.memory\": \"16g\",\n",
    "            \"spark.executor.cores\": 4,\n",
    "            \"spark.sql.shuffle.partitions\": 256,\n",
    "            \"spark.driver.maxResultSize\": \"2g\"\n",
    "        }\n",
    "    )\n",
    "\n",
    "spark_session.sparkContext.setLogLevel(\"ERROR\")\n",
    "\n",
    "clear_output()\n",
    "\n",
    "spark_session"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32c6d3de-14f4-425b-8ba6-00cc0c57b3b2",
   "metadata": {},
   "source": [
    "## query"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d85fba1f-e0c9-4bfa-aafe-03a33b57d4d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# manually curated file with information related to varioys iterations of the survey\n",
    "# such as links to category page, results page, category structure etc.\n",
    "\n",
    "cws_links = pd.read_csv('data/cws_page_links.tsv', sep='\\t')\n",
    "\n",
    "# load proposals data gathered in step 1\n",
    "with open('data/01-cws_proposals_data.json') as file:\n",
    "    cws_data = json.load(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "ceb37304-571f-41e4-9215-c4f277dba7c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "user_data_query = \"\"\"\n",
    "WITH\n",
    "    yearly_edits AS (\n",
    "        SELECT\n",
    "            event_user_text AS username,\n",
    "            wiki_db,\n",
    "            SUM(IF(wiki_db = 'wikidatawiki', 0.1, 1)) AS edit_count,\n",
    "            MAX(event_timestamp) AS last_edit\n",
    "        FROM \n",
    "            wmf.mediawiki_history\n",
    "        WHERE \n",
    "            snapshot='{HIVE_SNAPSHOT}' \n",
    "            AND NOT event_user_is_anonymous\n",
    "            AND event_type = 'create'\n",
    "            AND event_entity = 'revision'\n",
    "            AND event_user_text IN {USERS_LIST}\n",
    "            AND DATE(event_timestamp) BETWEEN DATE_SUB('{END_OF_DATA}', 365*2) AND DATE('{END_OF_DATA}')\n",
    "        GROUP BY \n",
    "            event_user_text, \n",
    "            wiki_db\n",
    "    ),\n",
    "\n",
    "    home_wiki_ranked AS (\n",
    "        SELECT \n",
    "            *,\n",
    "            ROW_NUMBER() OVER (\n",
    "                PARTITION BY username \n",
    "                ORDER BY edit_count DESC, last_edit DESC) AS rank\n",
    "        FROM yearly_edits\n",
    "    ),\n",
    "\n",
    "    -- homewiki is considered as the wiki where the user had highest number of edits during the two preceeding years\n",
    "    -- due to the granular nature of Wikidata edits, they were considered at the ratio of 10:1\n",
    "    home_wiki AS (\n",
    "        SELECT username, wiki_db AS home_wiki\n",
    "        FROM home_wiki_ranked\n",
    "        WHERE rank = 1\n",
    "    ),\n",
    "\n",
    "    edit_bucket_data AS (\n",
    "        SELECT\n",
    "            mwh.revision_id,\n",
    "            mwh.event_user_text,\n",
    "            mwh.event_user_revision_count AS edit_count,\n",
    "            CASE\n",
    "                WHEN mwh.event_user_revision_count < 100 THEN '0-99'\n",
    "                WHEN mwh.event_user_revision_count BETWEEN 100 AND 999 THEN '100-999'\n",
    "                WHEN mwh.event_user_revision_count BETWEEN 1000 AND 4999 THEN '1000-4999'\n",
    "                ELSE '5000+'\n",
    "            END AS edit_bucket,\n",
    "            mwh.event_timestamp,\n",
    "            ROW_NUMBER() OVER (\n",
    "                PARTITION BY mwh.event_user_text, mwh.wiki_db \n",
    "                ORDER BY mwh.event_timestamp DESC) AS rank,\n",
    "            CASE \n",
    "                WHEN mwh.wiki_db = 'metawiki' THEN NULL \n",
    "                ELSE ARRAY_DISTINCT(ARRAY_UNION(mwh.event_user_groups, mwh.event_user_groups_historical)) \n",
    "            END AS user_groups,\n",
    "            mwh.wiki_db,\n",
    "            hw.home_wiki\n",
    "        FROM \n",
    "            wmf.mediawiki_history mwh\n",
    "        JOIN \n",
    "            home_wiki hw \n",
    "            ON mwh.event_user_text = hw.username\n",
    "        WHERE \n",
    "            mwh.snapshot = '{HIVE_SNAPSHOT}'\n",
    "            AND mwh.event_user_text IN {USERS_LIST}\n",
    "            AND DATE(mwh.event_timestamp) <= DATE('{END_OF_DATA}')\n",
    "            AND (mwh.wiki_db = hw.home_wiki \n",
    "                OR mwh.wiki_db = 'metawiki')\n",
    "    ),\n",
    "\n",
    "    home_wiki_activity AS (\n",
    "        SELECT \n",
    "            * \n",
    "        FROM \n",
    "            edit_bucket_data\n",
    "        WHERE \n",
    "            wiki_db = home_wiki \n",
    "            AND rank = 1\n",
    "    ),\n",
    "    \n",
    "    meta_wiki_activity AS (\n",
    "        SELECT \n",
    "            * \n",
    "        FROM \n",
    "            edit_bucket_data\n",
    "        WHERE \n",
    "            wiki_db = 'metawiki' \n",
    "            AND rank = 1\n",
    "    )\n",
    "\n",
    "SELECT\n",
    "    hw.event_user_text AS username,\n",
    "    hw.home_wiki,\n",
    "    hw.edit_count AS hw_edit_count,\n",
    "    hw.edit_bucket AS hw_edit_bucket,\n",
    "    hw.user_groups AS hw_user_groups,\n",
    "    mw.edit_count AS mw_edit_count,\n",
    "    mw.edit_bucket AS mw_bucket\n",
    "FROM \n",
    "    home_wiki_activity hw\n",
    "JOIN \n",
    "    meta_wiki_activity mw \n",
    "    ON hw.event_user_text = mw.event_user_text\n",
    "\"\"\"\n",
    "\n",
    "guc_query = \"\"\"\n",
    "SELECT\n",
    "    gu_name AS username,\n",
    "    gu_registration AS reg_ts\n",
    "FROM\n",
    "    globaluser\n",
    "WHERE\n",
    "    gu_name IN {USERS_LIST}\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b193fc8c-6901-4366-bd5c-17212eb55b65",
   "metadata": {},
   "source": [
    "## Processing "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "528d892b-b211-41c0-80d0-fe3ff1f3e7f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# categorize users by year\n",
    "\n",
    "def users_by_year(data):\n",
    "    \n",
    "    # input: proposals data as inputs\n",
    "    # returns dict years as keys and list of usernames as values\n",
    "    \n",
    "    users_by_year = {}\n",
    "    \n",
    "    for year, categories in data.items():\n",
    "        \n",
    "        users = set()\n",
    "        \n",
    "        for category in categories.values():\n",
    "            for proposal in category.values():\n",
    "                for key in ['proposer', 'discussion_participants', 'voters']:\n",
    "                    participants = proposal.get(key, [])\n",
    "                    if participants != None:\n",
    "                        users.update(participants)\n",
    "        \n",
    "        users_by_year[year] = list(users)\n",
    "        \n",
    "    return users_by_year\n",
    "\n",
    "cws_users_by_year = users_by_year(cws_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "51a2803f-a51e-487d-ad12-e1b8b3526823",
   "metadata": {},
   "outputs": [],
   "source": [
    "# processes the data for each users as a dataframe\n",
    "# processing include datatypes conversion, age calculation from timestamps etc.\n",
    "\n",
    "def get_user_data(survey_year, cws_info=cws_links, usernames=cws_users_by_year, user_data_query=user_data_query, guc_query=guc_query):\n",
    "    \n",
    "    data_end = cws_info.query(\"\"\"year == @survey_year\"\"\")['data_end'].values[0]\n",
    "    participants = wmf.utils.sql_tuple(usernames[str(survey_year)])\n",
    "\n",
    "    users_data = wmf.spark.run(user_data_query.format(HIVE_SNAPSHOT=snapshot, END_OF_DATA=data_end, USERS_LIST=participants))\n",
    "    guc_data = wmf.mariadb.run(guc_query.format(USERS_LIST=participants), dbs='centralauth', use_x1=True)\n",
    "    \n",
    "    guc_data['reg_ts'] = pd.to_datetime(guc_data.reg_ts)\n",
    "    guc_data['reg_dt'] = guc_data['reg_ts'].apply(lambda x:x.date())\n",
    "    \n",
    "    guc_data['account_age'] = pd.to_datetime(data_end) - pd.to_datetime(guc_data['reg_dt'])\n",
    "    \n",
    "    guc_data = guc_data.assign(\n",
    "        account_age_days=lambda x: x['account_age'].dt.days,\n",
    "        account_age_months=lambda x: round(x['account_age_days'] / 30, 2),\n",
    "        account_age_years=lambda x: round(x['account_age_days'] / 365, 2)\n",
    "    )\n",
    "    \n",
    "    users_data = pd.merge(users_data, guc_data[['username', 'account_age_months', 'account_age_years']], how='left', on='username')\n",
    "\n",
    "    users_data['survey_year'] = survey_year\n",
    "    \n",
    "    return users_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "81656bc7-6f09-4d98-b34d-827c4b10a504",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                ]]]]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2015 data was extracted in 3.27 minutes.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                92]]]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2016 data was extracted in 3.11 minutes.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                56]]]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2017 data was extracted in 2.72 minutes.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                92]]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2019 data was extracted in 4.09 minutes.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                92]]]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2020 data was extracted in 4.29 minutes.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                192]]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021 data was extracted in 5.6 minutes.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                 256]]]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022 data was extracted in 5.49 minutes.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                192]]]]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023 data was extracted in 4.49 minutes.\n",
      "CPU times: user 6.43 s, sys: 1.07 s, total: 7.49 s\n",
      "Wall time: 33min 3s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "warnings.filterwarnings('ignore')\n",
    "users_data = pd.DataFrame()\n",
    "\n",
    "for year in range(2015, 2023+1):\n",
    "    if year != 2018:\n",
    "        \n",
    "        start_time = time.time()\n",
    "        \n",
    "        user_data_yearly = get_user_data(year)\n",
    "        user_data_yearly.to_csv(f'secrets/cws_user_data_{year}.tsv', sep='\\t')\n",
    "        \n",
    "        users_data = pd.concat([users_data, user_data_yearly], ignore_index=True)\n",
    "        users_data.to_csv(f'secrets/cws_user_data_merged.tsv', sep='\\t')\n",
    "        \n",
    "        end_time = time.time()\n",
    "        elapsed_time = round((end_time - start_time)/60, 2)\n",
    "        print(f\"{year} data was extracted in {elapsed_time} minutes.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "53ad75a3-7022-42b8-bfdf-428b91406b97",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 9308 entries, 0 to 9307\n",
      "Data columns (total 10 columns):\n",
      " #   Column              Non-Null Count  Dtype  \n",
      "---  ------              --------------  -----  \n",
      " 0   username            9308 non-null   object \n",
      " 1   home_wiki           9308 non-null   object \n",
      " 2   hw_edit_count       8676 non-null   float64\n",
      " 3   hw_edit_bucket      9308 non-null   object \n",
      " 4   hw_user_groups      8986 non-null   object \n",
      " 5   mw_edit_count       8920 non-null   float64\n",
      " 6   mw_bucket           9308 non-null   object \n",
      " 7   account_age_months  9308 non-null   float64\n",
      " 8   account_age_years   9308 non-null   float64\n",
      " 9   survey_year         9308 non-null   int64  \n",
      "dtypes: float64(4), int64(1), object(5)\n",
      "memory usage: 727.3+ KB\n"
     ]
    }
   ],
   "source": [
    "users_data.info()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
